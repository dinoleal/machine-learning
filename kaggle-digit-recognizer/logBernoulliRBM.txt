Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 1000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[  0   1   2   3   4   5   6   7   8   9]
 [107  96 124  90 102  89  97 105  93  97]]
Done!
Fit MinMaxScaler transform time (secs): 0.000
[BernoulliRBM] Iteration 1, pseudo-likelihood = -153.13, time = 0.34s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -133.24, time = 0.42s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -144.69, time = 0.38s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -144.24, time = 0.39s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -146.40, time = 0.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -125.99, time = 0.36s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -123.37, time = 0.37s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -108.17, time = 0.37s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -99.63, time = 0.37s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -112.28, time = 0.36s
Done!
Training time (secs): 4.159
Traing set: 
Done!
Prediction time (secs): 0.016
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9892    1.0000    0.9946        92
          1     0.9867    0.9737    0.9801        76
          2     0.9780    0.9674    0.9727        92
          3     0.9610    0.9737    0.9673        76
          4     0.9744    0.9870    0.9806        77
          5     0.9863    0.9730    0.9796        74
          6     0.9756    1.0000    0.9877        80
          7     0.9518    0.9634    0.9576        82
          8     0.9367    0.9487    0.9427        78
          9     0.9855    0.9315    0.9577        73

avg / total     0.9727    0.9725    0.9725       800


Test set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.7895    1.0000    0.8824        15
          1     0.9500    0.9500    0.9500        20
          2     0.9655    0.8750    0.9180        32
          3     1.0000    1.0000    1.0000        14
          4     0.9583    0.9200    0.9388        25
          5     0.8571    0.8000    0.8276        15
          6     0.8889    0.9412    0.9143        17
          7     0.8947    0.7391    0.8095        23
          8     0.7500    0.8000    0.7742        15
          9     0.8148    0.9167    0.8627        24

avg / total     0.8952    0.8900    0.8899       200

Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 5000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[  0   1   2   3   4   5   6   7   8   9]
 [494 558 545 480 477 469 516 506 477 478]]
Done!
Fit MinMaxScaler transform time (secs): 0.053
[BernoulliRBM] Iteration 1, pseudo-likelihood = -127.83, time = 1.66s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -114.21, time = 1.89s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -112.89, time = 1.86s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -102.91, time = 1.82s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -93.74, time = 1.85s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -104.74, time = 1.87s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -95.21, time = 1.86s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -89.82, time = 1.85s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -99.71, time = 1.79s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -90.20, time = 1.85s
Done!
Training time (secs): 21.502
Traing set: 
Done!
Prediction time (secs): 0.067
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9848    0.9873    0.9861       394
          1     0.9954    0.9819    0.9886       441
          2     0.9571    0.9658    0.9615       439
          3     0.9519    0.9493    0.9506       375
          4     0.9843    0.9715    0.9778       386
          5     0.9809    0.9497    0.9651       378
          6     0.9789    0.9905    0.9847       421
          7     0.9673    0.9552    0.9612       402
          8     0.9215    0.9681    0.9442       376
          9     0.9433    0.9433    0.9433       388

avg / total     0.9671    0.9667    0.9668      4000


Test set: 
Done!
Prediction time (secs): 0.017
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9691    0.9400    0.9543       100
          1     0.9741    0.9658    0.9700       117
          2     0.9196    0.9717    0.9450       106
          3     0.9490    0.8857    0.9163       105
          4     0.9438    0.9231    0.9333        91
          5     0.9540    0.9121    0.9326        91
          6     0.9400    0.9895    0.9641        95
          7     0.9596    0.9135    0.9360       104
          8     0.8922    0.9010    0.8966       101
          9     0.8200    0.9111    0.8632        90

avg / total     0.9337    0.9320    0.9323      1000

Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 10000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[   0    1    2    3    4    5    6    7    8    9]
 [ 991 1095 1045 1009  967  906 1003 1039  950  995]]
Done!
Fit MinMaxScaler transform time (secs): 0.098
[BernoulliRBM] Iteration 1, pseudo-likelihood = -116.63, time = 3.53s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -102.41, time = 3.71s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -100.15, time = 3.95s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -93.22, time = 3.62s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -84.74, time = 3.63s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -86.40, time = 3.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -86.67, time = 3.88s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -90.21, time = 3.79s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -86.93, time = 3.60s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -87.27, time = 3.71s
Done!
Training time (secs): 44.278
Traing set: 
Done!
Prediction time (secs): 0.132
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9851    0.9888    0.9870       805
          1     0.9909    0.9876    0.9892       885
          2     0.9744    0.9697    0.9721       825
          3     0.9565    0.9389    0.9476       819
          4     0.9765    0.9602    0.9683       779
          5     0.9590    0.9537    0.9563       712
          6     0.9743    0.9791    0.9767       813
          7     0.9652    0.9628    0.9640       806
          8     0.9265    0.9535    0.9398       753
          9     0.9387    0.9527    0.9456       803

avg / total     0.9653    0.9651    0.9652      8000


Test set: 
Done!
Prediction time (secs): 0.038
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9677    0.9677    0.9677       186
          1     0.9714    0.9714    0.9714       210
          2     0.9312    0.9227    0.9269       220
          3     0.9274    0.8737    0.8997       190
          4     0.9615    0.9309    0.9459       188
          5     0.9355    0.8969    0.9158       194
          6     0.9590    0.9842    0.9714       190
          7     0.9437    0.9356    0.9397       233
          8     0.8447    0.9391    0.8894       197
          9     0.8969    0.9062    0.9016       192

avg / total     0.9340    0.9330    0.9331      2000


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 42000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[   0    1    2    3    4    5    6    7    8    9]
 [4132 4684 4177 4351 4072 3795 4137 4401 4063 4188]]
Done!
Fit MinMaxScaler transform time (secs): 0.348
[BernoulliRBM] Iteration 1, pseudo-likelihood = -90.27, time = 14.27s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -91.63, time = 16.42s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -85.88, time = 18.55s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -82.98, time = 16.95s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -84.89, time = 16.07s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -85.64, time = 16.20s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.39, time = 15.78s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -82.00, time = 15.94s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -80.71, time = 15.80s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -81.67, time = 15.67s
Done!
Training time (secs): 197.456
Traing set: 
Done!
Prediction time (secs): 0.438
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9769    0.9831    0.9800      3316
          1     0.9891    0.9875    0.9883      3775
          2     0.9667    0.9667    0.9667      3331
          3     0.9452    0.9400    0.9426      3414
          4     0.9727    0.9462    0.9592      3233
          5     0.9561    0.9444    0.9502      3093
          6     0.9759    0.9803    0.9781      3352
          7     0.9699    0.9661    0.9680      3508
          8     0.9259    0.9452    0.9355      3228
          9     0.9250    0.9421    0.9335      3350

avg / total     0.9608    0.9607    0.9607     33600


Test set: 
Done!
Prediction time (secs): 0.109
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.9767    0.9779    0.9773       816
          1     0.9836    0.9912    0.9874       909
          2     0.9696    0.9421    0.9556       846
          3     0.9427    0.9306    0.9366       937
          4     0.9717    0.9416    0.9564       839
          5     0.9633    0.9359    0.9494       702
          6     0.9721    0.9771    0.9746       785
          7     0.9670    0.9518    0.9594       893
          8     0.8945    0.9545    0.9235       835
          9     0.9076    0.9379    0.9225       838

avg / total     0.9548    0.9542    0.9543      8400


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 1000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[  0   1   2   3   4   5   6   7   8   9]
 [107  96 124  90 102  89  97 105  93  97]]
Done!
Fit MinMaxScaler transform time (secs): 0.015
[ 0.09970463  0.07542846  0.06014348  0.05477071  0.04685712  0.04464145
  0.03249051  0.02892218  0.02756132  0.02434666  0.02255439  0.01989246
  0.01811031  0.01712279  0.01615998  0.0149236   0.01413976  0.0133436
  0.01168899  0.01130833  0.01065675  0.01018775  0.00976819  0.0093313
  0.00913495  0.00836832  0.00823165  0.00795272  0.00728204  0.00712798
  0.00666459  0.00662843  0.00617452  0.0059818   0.00563298  0.00537264
  0.00515082  0.00495734  0.00482133  0.00457585  0.0044286   0.00436422
  0.00421783  0.00406227  0.00394718  0.00390422  0.00380792  0.00360077
  0.00346856  0.0033972 ]
Done!
Fit PCA transform time (secs): 0.258
[BernoulliRBM] Iteration 1, pseudo-likelihood = -1336.31, time = 0.05s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -2438.30, time = 0.13s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -2832.75, time = 0.10s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -5139.31, time = 0.11s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -4391.41, time = 0.06s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -9372.55, time = 0.12s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -7491.07, time = 0.11s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -15500.60, time = 0.12s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -7579.52, time = 0.06s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -18959.59, time = 0.12s
Done!
Training time (secs): 1.450
Traing set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.2812    0.9783    0.4369        92
          1     0.1984    0.9868    0.3304        76
          2     0.8333    0.2174    0.3448        92
          3     0.9231    0.1579    0.2697        76
          4     0.8125    0.1688    0.2796        77
          5     0.5000    0.0135    0.0263        74
          6     0.6667    0.0750    0.1348        80
          7     0.5200    0.1585    0.2430        82
          8     0.9000    0.1154    0.2045        78
          9     0.6667    0.0274    0.0526        73

avg / total     0.6277    0.3013    0.2394       800


Test set: 
Done!
Prediction time (secs): 0.000

Warning (from warnings module):
  File "C:\Python27\lib\site-packages\sklearn\metrics\classification.py", line 1074
    'precision', 'predicted', average, warn_for)
UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.2083    1.0000    0.3448        15
          1     0.2000    1.0000    0.3333        20
          2     0.3636    0.1250    0.1860        32
          3     1.0000    0.0714    0.1333        14
          4     0.7500    0.1200    0.2069        25
          5     0.0000    0.0000    0.0000        15
          6     0.0000    0.0000    0.0000        17
          7     0.3636    0.1739    0.2353        23
          8     0.0000    0.0000    0.0000        15
          9     0.0000    0.0000    0.0000        24

avg / total     0.2994    0.2350    0.1512       200


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 5000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[  0   1   2   3   4   5   6   7   8   9]
 [494 558 545 480 477 469 516 506 477 478]]
Done!
Fit MinMaxScaler transform time (secs): 0.047
[ 0.09695577  0.07112179  0.06099859  0.05525034  0.04849025  0.04335393
  0.03219146  0.0285022   0.0281952   0.02344721  0.02171763  0.02043561
  0.01744285  0.01703605  0.01598681  0.0145585   0.01316614  0.01280298
  0.01180296  0.01153037  0.01098462  0.01049946  0.00985493  0.00947278
  0.00890972  0.00844628  0.00820242  0.00795189  0.00732042  0.00677182
  0.00667498  0.00653126  0.0060238   0.0059005   0.00550833  0.00535837
  0.00511172  0.00497831  0.00477214  0.00462382  0.00456078  0.00438946
  0.00436991  0.00407798  0.00388512  0.00379501  0.00358152  0.00356736
  0.00337233  0.00319064]
Done!
Fit PCA transform time (secs): 0.662
[BernoulliRBM] Iteration 1, pseudo-likelihood = -6376.39, time = 0.22s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -11540.33, time = 0.34s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -16019.38, time = 0.32s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -23526.03, time = 0.33s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -30914.31, time = 0.30s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -33541.67, time = 0.36s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -43010.81, time = 0.33s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -42134.54, time = 0.38s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -61902.74, time = 0.36s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -59901.25, time = 0.38s
Done!
Training time (secs): 8.903
Traing set: 
Done!
Prediction time (secs): 0.047
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.4908    0.6777    0.5693       394
          1     0.7105    0.9683    0.8196       441
          2     0.7685    0.3781    0.5069       439
          3     0.4205    0.7333    0.5345       375
          4     0.6559    0.3161    0.4266       386
          5     0.5706    0.2566    0.3540       378
          6     0.4685    0.4418    0.4548       421
          7     0.3516    0.7488    0.4785       402
          8     0.5833    0.2234    0.3231       376
          9     0.5129    0.3067    0.3839       388

avg / total     0.5569    0.5110    0.4904      4000


Test set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.4338    0.5900    0.5000       100
          1     0.7403    0.9744    0.8413       117
          2     0.5185    0.2642    0.3500       106
          3     0.4085    0.6381    0.4981       105
          4     0.3000    0.1648    0.2128        91
          5     0.3023    0.1429    0.1940        91
          6     0.3529    0.3158    0.3333        95
          7     0.3062    0.6154    0.4089       104
          8     0.4615    0.1782    0.2571       101
          9     0.2727    0.2000    0.2308        90

avg / total     0.4192    0.4260    0.3958      1000


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 10000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[   0    1    2    3    4    5    6    7    8    9]
 [ 991 1095 1045 1009  967  906 1003 1039  950  995]]
Done!
Fit MinMaxScaler transform time (secs): 0.079
[ 0.09684205  0.07204279  0.06198608  0.05421242  0.04818008  0.04278435
  0.03210262  0.02871533  0.02818841  0.02351758  0.02110976  0.02030664
  0.01736905  0.01703758  0.01591722  0.0146375   0.01320362  0.01307263
  0.01171107  0.01168642  0.01095618  0.01035541  0.00974926  0.00917344
  0.00889851  0.00843267  0.0082379   0.00780694  0.00737713  0.00685244
  0.0067294   0.00645679  0.00609894  0.00584133  0.0055445   0.00533571
  0.00511238  0.0049028   0.00479541  0.00460973  0.00449928  0.00437337
  0.00428573  0.00400683  0.00391353  0.00379063  0.00361334  0.00348044
  0.00341823  0.00319392]
Done!
Fit PCA transform time (secs): 1.141
[BernoulliRBM] Iteration 1, pseudo-likelihood = -11880.78, time = 0.43s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -21285.31, time = 0.62s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -23962.22, time = 0.61s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -39482.24, time = 0.62s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -44596.10, time = 0.66s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -68157.23, time = 0.72s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -58424.79, time = 0.69s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -90697.16, time = 0.71s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -95315.56, time = 0.67s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -104675.72, time = 0.73s
Done!
Training time (secs): 13.135
Traing set: 
Done!
Prediction time (secs): 0.100
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.2460    0.9764    0.3930       805
          1     0.2382    0.9966    0.3846       885
          2     0.7308    0.0461    0.0867       825
          3     0.5852    0.2808    0.3795       819
          4     0.4615    0.1078    0.1748       779
          5     0.7917    0.0267    0.0516       712
          6     0.7419    0.0283    0.0545       813
          7     0.4706    0.0794    0.1359       806
          8     0.7188    0.0305    0.0586       753
          9     0.4190    0.1320    0.2008       803

avg / total     0.5343    0.2819    0.1964      8000


Test set: 
Done!
Prediction time (secs): 0.026
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.2415    0.9892    0.3882       186
          1     0.2174    1.0000    0.3571       210
          2     0.4286    0.0273    0.0513       220
          3     0.5109    0.2474    0.3333       190
          4     0.3077    0.0638    0.1057       188
          5     0.2500    0.0052    0.0101       194
          6     0.0000    0.0000    0.0000       190
          7     0.4444    0.0858    0.1439       233
          8     0.3333    0.0051    0.0100       197
          9     0.2838    0.1094    0.1579       192

avg / total     0.3060    0.2510    0.1547      2000


>>> 
 RESTART: C:\Users\Philip\Documents\GitHub\machine-learning\kaggle-digit-recognizer\digit_recognizer.py 
Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 42000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[   0    1    2    3    4    5    6    7    8    9]
 [4132 4684 4177 4351 4072 3795 4137 4401 4063 4188]]
Done!
Fit MinMaxScaler transform time (secs): 0.364
[ 0.09748496  0.07159942  0.06145625  0.05379059  0.0489404   0.04303019
  0.03276902  0.02891973  0.02766777  0.02348765  0.0209923   0.02058908
  0.01702477  0.01692711  0.01581055  0.01483173  0.01319628  0.0128267
  0.01187922  0.01152703  0.01072143  0.01015154  0.00964859  0.00912805
  0.00887601  0.00838729  0.00811819  0.00777371  0.00740602  0.00686631
  0.00657953  0.0063877   0.0059934   0.00588887  0.0056431   0.00540943
  0.00509199  0.00487483  0.00475548  0.00466524  0.00452932  0.00444969
  0.00418237  0.00397488  0.00384525  0.00374903  0.00360997  0.00348507
  0.00336473  0.00320724]
Done!
Fit PCA transform time (secs): 4.082
[BernoulliRBM] Iteration 1, pseudo-likelihood = -50059.19, time = 1.87s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -104045.55, time = 2.76s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -150531.24, time = 2.90s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -215835.60, time = 3.06s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -243583.82, time = 3.01s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -292315.93, time = 3.01s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -357197.77, time = 3.08s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -392229.61, time = 3.03s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -428607.78, time = 2.96s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -482609.91, time = 2.95s
Done!
Training time (secs): 59.002
Traing set: 
Done!
Prediction time (secs): 0.470
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.2413    0.9816    0.3874      3316
          1     0.2483    0.9987    0.3977      3775
          2     0.5940    0.0237    0.0456      3331
          3     0.5154    0.2545    0.3408      3414
          4     0.4537    0.0606    0.1070      3233
          5     0.6279    0.0087    0.0172      3093
          6     0.6623    0.0152    0.0297      3352
          7     0.4124    0.1765    0.2472      3508
          8     0.6000    0.0130    0.0255      3228
          9     0.4018    0.1185    0.1830      3350

avg / total     0.4713    0.2769    0.1834     33600


Test set: 
Done!
Prediction time (secs): 0.109
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0     0.2360    0.9767    0.3802       816
          1     0.2413    0.9989    0.3887       909
          2     0.3793    0.0130    0.0251       846
          3     0.5265    0.2647    0.3523       937
          4     0.3028    0.0393    0.0696       839
          5     0.2500    0.0043    0.0084       702
          6     0.4000    0.0102    0.0199       785
          7     0.3586    0.1377    0.1990       893
          8     0.3889    0.0084    0.0164       835
          9     0.3023    0.0931    0.1423       838

avg / total     0.3414    0.2638    0.1673      8400