Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 1000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[  0   1   2   3   4   5   6   7   8   9]
 [107  96 124  90 102  89  97 105  93  97]]
Done!
Fit MinMaxScaler transform time (secs): 0.016
[BernoulliRBM] Iteration 1, pseudo-likelihood = -180.22, time = 0.33s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -142.61, time = 0.42s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -145.82, time = 0.39s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -144.33, time = 0.40s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -132.30, time = 0.36s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -106.58, time = 0.36s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -135.04, time = 0.37s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -113.09, time = 0.36s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -135.93, time = 0.38s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -118.75, time = 0.36s
Done!
Training time (secs): 4.190
LR-RBM Traing set: 
Done!
Prediction time (secs): 0.002
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.98925   1.00000   0.99459        92
          1    0.98667   0.97368   0.98013        76
          2    0.98889   0.96739   0.97802        92
          3    0.96053   0.96053   0.96053        76
          4    0.96203   0.98701   0.97436        77
          5    0.96053   0.98649   0.97333        74
          6    0.98765   1.00000   0.99379        80
          7    0.96341   0.96341   0.96341        82
          8    0.94872   0.94872   0.94872        78
          9    0.97143   0.93151   0.95105        73

avg / total    0.97257   0.97250   0.97244       800


LR-RBM Test set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.83333   1.00000   0.90909        15
          1    0.95000   0.95000   0.95000        20
          2    0.90000   0.84375   0.87097        32
          3    1.00000   0.92857   0.96296        14
          4    0.87500   0.84000   0.85714        25
          5    1.00000   0.80000   0.88889        15
          6    0.84211   0.94118   0.88889        17
          7    0.90000   0.78261   0.83721        23
          8    0.76471   0.86667   0.81250        15
          9    0.77778   0.87500   0.82353        24

avg / total    0.88164   0.87500   0.87535       200


LR Traing set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    1.00000   1.00000   1.00000        92
          1    0.98701   1.00000   0.99346        76
          2    1.00000   1.00000   1.00000        92
          3    1.00000   1.00000   1.00000        76
          4    1.00000   1.00000   1.00000        77
          5    1.00000   1.00000   1.00000        74
          6    1.00000   1.00000   1.00000        80
          7    1.00000   0.98780   0.99387        82
          8    1.00000   1.00000   1.00000        78
          9    1.00000   1.00000   1.00000        73

avg / total    0.99877   0.99875   0.99875       800


LR Test set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.83333   1.00000   0.90909        15
          1    0.90476   0.95000   0.92683        20
          2    1.00000   0.75000   0.85714        32
          3    1.00000   0.85714   0.92308        14
          4    0.84000   0.84000   0.84000        25
          5    0.66667   0.66667   0.66667        15
          6    0.65217   0.88235   0.75000        17
          7    0.85714   0.78261   0.81818        23
          8    0.73333   0.73333   0.73333        15
          9    0.84615   0.91667   0.88000        24

avg / total    0.84852   0.83500   0.83606       200


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 5000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[  0   1   2   3   4   5   6   7   8   9]
 [494 558 545 480 477 469 516 506 477 478]]
Done!
Fit MinMaxScaler transform time (secs): 0.047
[BernoulliRBM] Iteration 1, pseudo-likelihood = -124.14, time = 1.70s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -111.16, time = 1.89s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -105.26, time = 1.88s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -98.83, time = 1.81s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -101.80, time = 1.82s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -100.32, time = 1.83s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -91.85, time = 1.85s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -99.01, time = 1.83s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -96.91, time = 1.82s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -87.12, time = 1.83s
Done!
Training time (secs): 21.503
LR-RBM Traing set: 
Done!
Prediction time (secs): 0.085
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.97980   0.98477   0.98228       394
          1    0.99544   0.99093   0.99318       441
          2    0.96568   0.96128   0.96347       439
          3    0.95430   0.94667   0.95047       375
          4    0.96891   0.96891   0.96891       386
          5    0.96524   0.95503   0.96011       378
          6    0.98118   0.99050   0.98582       421
          7    0.97494   0.96766   0.97129       402
          8    0.94560   0.97074   0.95801       376
          9    0.94819   0.94330   0.94574       388

avg / total    0.96853   0.96850   0.96849      4000


LR-RBM Test set: 
Done!
Prediction time (secs): 0.016
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.95000   0.95000   0.95000       100
          1    0.97458   0.98291   0.97872       117
          2    0.93519   0.95283   0.94393       106
          3    0.91262   0.89524   0.90385       105
          4    0.93258   0.91209   0.92222        91
          5    0.96471   0.90110   0.93182        91
          6    0.91919   0.95789   0.93814        95
          7    0.94286   0.95192   0.94737       104
          8    0.93000   0.92079   0.92537       101
          9    0.83871   0.86667   0.85246        90

avg / total    0.93143   0.93100   0.93102      1000


LR Traing set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.99242   0.99746   0.99494       394
          1    0.98190   0.98413   0.98301       441
          2    0.97917   0.96355   0.97130       439
          3    0.97067   0.97067   0.97067       375
          4    0.96606   0.95855   0.96229       386
          5    0.96817   0.96561   0.96689       378
          6    0.98353   0.99287   0.98818       421
          7    0.96350   0.98507   0.97417       402
          8    0.95213   0.95213   0.95213       376
          9    0.94517   0.93299   0.93904       388

avg / total    0.97072   0.97075   0.97071      4000


LR Test set: 
Done!
Prediction time (secs): 0.016
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.90476   0.95000   0.92683       100
          1    0.92562   0.95726   0.94118       117
          2    0.87963   0.89623   0.88785       106
          3    0.90526   0.81905   0.86000       105
          4    0.93407   0.93407   0.93407        91
          5    0.88750   0.78022   0.83041        91
          6    0.91837   0.94737   0.93264        95
          7    0.89524   0.90385   0.89952       104
          8    0.87368   0.82178   0.84694       101
          9    0.79412   0.90000   0.84375        90

avg / total    0.89289   0.89200   0.89141      1000


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 10000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[   0    1    2    3    4    5    6    7    8    9]
 [ 991 1095 1045 1009  967  906 1003 1039  950  995]]
Done!
Fit MinMaxScaler transform time (secs): 0.086
[BernoulliRBM] Iteration 1, pseudo-likelihood = -111.91, time = 3.42s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -100.08, time = 3.61s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -99.22, time = 3.61s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -91.23, time = 3.73s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -88.23, time = 3.61s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -87.84, time = 3.60s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -87.79, time = 3.83s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -90.71, time = 3.90s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -84.22, time = 3.90s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -86.04, time = 3.97s
Done!
Training time (secs): 44.568
LR-RBM Traing set: 
Done!
Prediction time (secs): 0.100
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.97317   0.99130   0.98215       805
          1    0.98977   0.98418   0.98697       885
          2    0.96224   0.95758   0.95990       825
          3    0.94821   0.93895   0.94356       819
          4    0.96565   0.97433   0.96997       779
          5    0.95540   0.93258   0.94385       712
          6    0.97327   0.98524   0.97922       813
          7    0.96569   0.94293   0.95417       806
          8    0.92506   0.95086   0.93779       753
          9    0.93275   0.93275   0.93275       803

avg / total    0.95968   0.95962   0.95959      8000


LR-RBM Test set: 
Done!
Prediction time (secs): 0.016
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.95767   0.97312   0.96533       186
          1    0.97115   0.96190   0.96651       210
          2    0.94064   0.93636   0.93850       220
          3    0.95580   0.91053   0.93261       190
          4    0.95187   0.94681   0.94933       188
          5    0.95109   0.90206   0.92593       194
          6    0.95876   0.97895   0.96875       190
          7    0.96413   0.92275   0.94298       233
          8    0.87500   0.95939   0.91525       197
          9    0.88442   0.91667   0.90026       192

avg / total    0.94153   0.94050   0.94061      2000


LR Traing set: 
Done!
Prediction time (secs): 0.023
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.98155   0.99130   0.98640       805
          1    0.97101   0.98418   0.97755       885
          2    0.95946   0.94667   0.95302       825
          3    0.94254   0.94139   0.94197       819
          4    0.94804   0.96021   0.95408       779
          5    0.94034   0.92978   0.93503       712
          6    0.97199   0.98155   0.97674       813
          7    0.96264   0.95906   0.96085       806
          8    0.93225   0.91368   0.92287       753
          9    0.92653   0.92653   0.92653       803

avg / total    0.95414   0.95425   0.95417      8000


LR Test set: 
Done!
Prediction time (secs): 0.000
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.95263   0.97312   0.96277       186
          1    0.89912   0.97619   0.93607       210
          2    0.91121   0.88636   0.89862       220
          3    0.88587   0.85789   0.87166       190
          4    0.90306   0.94149   0.92188       188
          5    0.86111   0.79897   0.82888       194
          6    0.93617   0.92632   0.93122       190
          7    0.93833   0.91416   0.92609       233
          8    0.85500   0.86802   0.86146       197
          9    0.87047   0.87500   0.87273       192

avg / total    0.90184   0.90200   0.90153      2000


Train data loaded!
Test data loaded!
Dataset train --------
Total number of digits (images): 42000
Total number of features: 784
Digit image width: 28
Digit image height: 28
Unique labels with count:
[[   0    1    2    3    4    5    6    7    8    9]
 [4132 4684 4177 4351 4072 3795 4137 4401 4063 4188]]
Done!
Fit MinMaxScaler transform time (secs): 0.390
[BernoulliRBM] Iteration 1, pseudo-likelihood = -97.90, time = 14.03s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -88.13, time = 15.80s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -89.14, time = 15.39s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -82.95, time = 15.18s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -80.13, time = 15.22s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -83.13, time = 15.03s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -86.30, time = 15.90s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -85.10, time = 15.69s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -83.38, time = 15.78s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -81.15, time = 15.62s
Done!
Training time (secs): 191.872
LR-RBM Traing set: 
Done!
Prediction time (secs): 0.368
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.97776   0.98100   0.97938      3316
          1    0.98675   0.98649   0.98662      3775
          2    0.96429   0.96458   0.96443      3331
          3    0.93798   0.93029   0.93412      3414
          4    0.96565   0.95639   0.96099      3233
          5    0.95247   0.95247   0.95247      3093
          6    0.98265   0.98001   0.98133      3352
          7    0.97223   0.95810   0.96511      3508
          8    0.91780   0.94424   0.93083      3228
          9    0.93284   0.93701   0.93492      3350

avg / total    0.95957   0.95943   0.95947     33600


LR-RBM Test set: 
Done!
Prediction time (secs): 0.097
Classification report for classifier Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.1, n_components=256, n_iter=10,
       random_state=None, verbose=1)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False))]):
             precision    recall  f1-score   support

          0    0.98153   0.97672   0.97912       816
          1    0.98255   0.99120   0.98686       909
          2    0.96879   0.95390   0.96129       846
          3    0.93312   0.93810   0.93560       937
          4    0.96140   0.94994   0.95564       839
          5    0.95080   0.93590   0.94329       702
          6    0.96954   0.97325   0.97139       785
          7    0.96914   0.94961   0.95928       893
          8    0.91696   0.95210   0.93420       835
          9    0.91844   0.92721   0.92280       838

avg / total    0.95523   0.95500   0.95505      8400


LR Traing set: 
Done!
Prediction time (secs): 0.054
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.96160   0.98160   0.97150      3316
          1    0.95485   0.98040   0.96746      3775
          2    0.93303   0.91174   0.92226      3331
          3    0.91078   0.90305   0.90690      3414
          4    0.93360   0.94371   0.93862      3233
          5    0.90640   0.89234   0.89932      3093
          6    0.95901   0.97017   0.96456      3352
          7    0.94762   0.94384   0.94573      3508
          8    0.89918   0.88693   0.89301      3228
          9    0.90865   0.89970   0.90415      3350

avg / total    0.93208   0.93235   0.93215     33600


LR Test set: 
Done!
Prediction time (secs): 0.013
Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False):
             precision    recall  f1-score   support

          0    0.96252   0.97549   0.96896       816
          1    0.95498   0.98020   0.96743       909
          2    0.91677   0.88534   0.90078       846
          3    0.89712   0.86553   0.88104       937
          4    0.91259   0.93325   0.92280       839
          5    0.84831   0.86040   0.85431       702
          6    0.93883   0.95796   0.94830       785
          7    0.92744   0.91601   0.92169       893
          8    0.88358   0.86347   0.87341       835
          9    0.88941   0.90215   0.89573       838

avg / total    0.91419   0.91440   0.91417      8400